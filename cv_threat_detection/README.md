
# ğŸ CV Threat Detection â€” YOLO11 Hornet/Wasp/Bee Watcher

This project is the computer vision module of the apiculture (beekeeping) monitoring system. Its main goal is to detect threats (hornets, wasps, etc.) near beehives using a camera and alert the user in real time.

## ğŸ“¦ Project Structure

```
cv_threat_detection/
â”‚
â”œâ”€â”€ models/         # YOLO model weights and model info scripts
â”œâ”€â”€ notebooks/      # Jupyter notebooks for training and experiments
â”œâ”€â”€ results/        # Output videos, images, logs from inference
â”œâ”€â”€ src/            # Main source code (detection, UI, utils)
â”œâ”€â”€ training_data/  # Labeled images and dataset config for training
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```

## ğŸ” Folder Details

- **models/**: Contains YOLO model weights (`yolov11l.pt`, `yolov8l.pt`) and utility scripts like `get_model_info.py` for inspecting model details.
- **notebooks/**: Jupyter notebooks for training and evaluating models. Useful for research and prototyping.
- **results/**: Stores outputs generated by the detection pipeline, such as processed videos, images, and logs.
- **src/**: Core source code for the detection system, including configuration, inference logic, postprocessing, multi-feed utilities, and the Streamlit dashboard UI.
- **training_data/**: Contains the dataset used for training/validation/testing, organized in YOLO format, and a `data.yaml` config file.

## ğŸš€ How It Works

1. **Model Loading**: The system loads a YOLO model (configurable in `src/config.py`) for object detection.
2. **Inference**: Video frames from a webcam or file are processed by the model to detect hornets, wasps, and bees.
3. **Postprocessing**: Detected objects are filtered, and bounding boxes/labels are drawn on the frames.
4. **UI**: The Streamlit dashboard (`src/streamlit_app.py`) provides a live, multi-feed view for real-time monitoring.
5. **Results**: Outputs can be saved to the `results/` folder for later review.

## ğŸ› ï¸ Setup & Usage

1. **Install dependencies**:
	```sh
	pip install -r requirements.txt
	```
2. **(Optional) Create a virtual environment**:
	```sh
	python -m venv myenv
	myenv\Scripts\activate
	```
3. **Run the Streamlit dashboard**:
	```sh
	streamlit run src/streamlit_app.py
	```
4. **Test single-feed inference** (for debugging):
	```sh
	python src/main_testing.py
	```

## ğŸ“ Configuration
- All settings (model path, thresholds, device, etc.) are managed in `src/config.py`.
- Dataset configuration for training is in `training_data/data.yaml`.

## ğŸ§  Model Training
- Use the notebooks in `notebooks/` to train or fine-tune YOLO models on your dataset.
- Place new weights in `models/` and update the path in `config.py`.

## ğŸ“‚ Data Format
- Follows standard YOLO dataset structure: `images/` and `labels/` for train/val/test splits, with a `data.yaml` file describing classes and paths.

## ğŸ¤ Contribution
- Modular codebase: add new models, postprocessing, or UI features easily.
- Keep results, models, and data organized in their respective folders.

## ğŸ§¹ Version Control
- Ignore virtual environments, model weights, and cache files (see `.gitignore`).

---

**This project is part of a larger apiculture monitoring system.**

For questions or contributions, see the individual folder READMEs for more details on each component.
```

Once itâ€™s active, install the project deps:

```bash
pip install -r requirements.txt
```

Then install the right PyTorch version for your system (GPU/CPU/Jetson/Pi).

To exit the venv:
```
deactivate
```


These include:
- ultralytics (for YOLO11)
- opencv
- numpy, pillow
- matplotlib, pyyaml, psutil  

### Step 2: Install PyTorch (depends on your machine)

PyTorch wheels are different based on GPU/CPU/platform, so itâ€™s NOT included in `requirements.txt` (this avoids breaking Jetson/Pi installs).

Pick the right one:

#### ğŸ–¥ï¸ Windows / Linux (NVIDIA GPU)
```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### ğŸ’» CPU-only (regular laptops)
```
pip install torch torchvision torchaudio
```

#### ğŸš€ Jetson (Nano / Orin)  
Use NVIDIAâ€™s official wheel:
```
sudo apt-get install python3-pip libopenblas-base libopenmpi-dev
pip install numpy==1.23.5
pip install https://developer.download.nvidia.com/compute/redist/jp/v512/pytorch/torch-2.1.0-cp38-cp38-linux_aarch64.whl
```

#### ğŸ“ Raspberry Pi (ARM)
```
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

After that, YOLO will run on basically anything.

---

## ğŸ“¦ Adding your model

Drop your YOLO11 weights here:

```
cv_threat_detection/models/yolo11m_640.pt
```

Then update this line in `config.py`:

```python
MODEL_PATH = "../models/yolo11m_640.pt"
```

Swap models anytime (1024 or small variant) without touching the code.

---

## âš™ï¸ Configuring the system

Everything lives in:

```
src/config.py
```

A few important ones:

```python
SOURCE = 0              # webcam; or replace with "file.mp4"
MODEL_PATH = "../models/yolo11m_640.pt"
DEVICE = "cuda"         # or "cpu"
CONF_THRESHOLD = 0.25
IOU_THRESHOLD = 0.45
SHOW_WINDOW = True
SAVE_OUTPUT = False
```

If you want better small-object detection:

```python
USE_TILING = True
TILE_SIZE = 640
TILE_OVERLAP = 0.2
```

Tiling costs more compute but picks up tiny hornets that YOLO sometimes misses.

---

## â–¶ï¸ Running the detector

From inside the project folder:

```
python src/main.py
```

You should get a webcam window with boxes drawn around insects.  
Press **Q** to quit.

To run on a video:

```python
SOURCE = "hive_cam.mp4"
```

in `config.py`.

To save output video:

```python
SAVE_OUTPUT = True
OUTPUT_PATH = "../results/output.mp4"
```

---

## ğŸ“ Training your own models

Check the `notebooks/` folder for:
- training scripts  
- evaluation  
- comparison between models (640 vs 1024, s vs m)

We used 4 YOLO11 models for experiments, but for real deployment the 640-resolution medium model performed best.

---

## ğŸŒŸ Extra Notes (useful later)

- If FPS drops on older hardware, reduce `IMG_SIZE` in config.
- Jetson supports TensorRT export if you want even more speed.
- Raspberry Pi will run slower but still handles 640 model with CPU inference.

---

If you want to add alerts (email / buzzer / Telegram bot), logging, or a better UI, the structure here makes it pretty easy to expand.

Happy bee-protecting ğŸğŸ”¥
